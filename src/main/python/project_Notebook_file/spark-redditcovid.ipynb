{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": "import org.apache.spark",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "val path_to_bigDatasets = \"../../../../datasets/big/\"\n",
    "val path_to_datasets = \"../../../../datasets/\"\n",
    "\n",
    "val path_Fullml_posts = path_to_bigDatasets + \"the-reddit-covid-dataset-posts.csv\"\n",
    "val path_Fullml_comments = path_to_bigDatasets + \"the-reddit-covid-dataset-comments.csv\"\n",
    "\n",
    "val path_sample_posts = path_to_datasets + \"postsSample.csv\"\n",
    "val path_sample_comments = path_to_datasets + \"commentsSample.csv\""
   ],
   "id": "e3447d001ccfc3b4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import java.util.Calendar\n",
    "import java.text.SimpleDateFormat\n",
    "import org.apache.spark.sql.SaveMode\n",
    "import org.apache.spark.HashPartitioner\n",
    "\n",
    "object CovidConversationsParser {\n",
    "\n",
    "    val commaSplit = \",\"\n",
    "    val quotes = \"\\\"\"\n",
    "\n",
    "    /** Convert from timestamp (String) to Month + day (String) */\n",
    "    def monthDayFromTimestamp(timestamp: String): String = {\n",
    "        val cal = Calendar.getInstance()\n",
    "        cal.setTimeInMillis(timestamp.trim.toLong * 1000L)\n",
    "        val format = new SimpleDateFormat(\"MMMM\")\n",
    "        format.format(cal.getTime()) + \": \" + cal.get(Calendar.DAY_OF_MONTH)\n",
    "    }\n",
    "\n",
    "    /** Function to parse reddit posts\n",
    "    *\n",
    "    *  @param line line that has to be parsed\n",
    "    *  @return tuple containing id,subreddit.id,subreddit.name,subreddit.nsfw,created_utc,permalink,domain,url,selftext,title,score. none in case of input errors\n",
    "    */\n",
    "    def parseRedditPost(line: String): Option[(String, String, String, Boolean, String, String, String, String, String, String, Int)] = {\n",
    "        try {\n",
    "            val input = line.split(commaSplit)\n",
    "            if(input.size != 12) {\n",
    "                return Some((\"\", \"\", \"\", false, \"\", \"\", \"\", \"\", \"\", \"\", -1))\n",
    "            }\n",
    "            var url = \"None\"\n",
    "            if(input(8).trim.nonEmpty) {\n",
    "                url = input(8).trim\n",
    "            }\n",
    "            var selftext = \"None\"\n",
    "            if(input(9).trim.nonEmpty) {\n",
    "                selftext = input(9).trim\n",
    "            }\n",
    "            val number = input(11).trim.replaceAll(quotes, \"\")\n",
    "            Some((input(1).trim, input(2).trim, input(3).trim, input(4).trim.toBoolean, monthDayFromTimestamp(input(5)), input(6).trim, input(7).trim, url, selftext, input(10).trim , number.toInt))\n",
    "        } catch {\n",
    "            case _: Exception => None\n",
    "        }\n",
    "    }\n",
    "\n",
    "    /** Function to parse reddit comments\n",
    "    *\n",
    "    *  @param line line that has to be parsed\n",
    "    *  @return tuple containing id,subreddit.id,subreddit.name,subreddit.nsfw,created_utc,permalink,body,sentiment,score. none in case of input errors\n",
    "    */\n",
    "    def parseRedditComment(line: String): Option[(String, String, String, Boolean, String, String, String, Double, Int)] = {\n",
    "        try {\n",
    "            val input = line.split(commaSplit)\n",
    "            if(input.size != 10) {\n",
    "                return Some((\"\", \"\", \"\", false, \"\", \"\", \"\", -0.1, -1))\n",
    "            }\n",
    "            val number = input(9).trim.replaceAll(quotes, \"\")\n",
    "            Some((input(1).trim, input(2).trim, input(3).trim, input(4).trim.toBoolean, monthDayFromTimestamp(input(5)), input(6).trim, input(7).trim, input(8).trim.toDouble, number.toInt))\n",
    "        } catch {\n",
    "            case _: Exception => None\n",
    "        }\n",
    "    }\n",
    "}"
   ],
   "id": "c887d7e89a51786e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "//per recuperare dei samples dei files\n",
    "//sc.textFile(path_Fullml_posts).sample(false, 0.05).coalesce(1).toDF().write.format(\"csv\").mode(SaveMode.Overwrite).save(\"../../../../datasets/sample\")\n",
    "sc.textFile(path_Fullml_comments).sample(false, 0.02).coalesce(1).toDF().write.format(\"csv\").mode(SaveMode.Overwrite).save(\"../../../../datasets/sample\")"
   ],
   "id": "6ef50ca52909c10e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "/*getting RDDs of Comments and Posts*/\n",
    "val rddPosts = sc.textFile(path_sample_posts).flatMap(CovidConversationsParser.parseRedditPost).filter(x => x != (\"\",\"\",\"\",false, \"\",\"\",\"\",\"\",\"\",\"\",-1))\n",
    "val rddComments = sc.textFile(path_sample_comments).flatMap(CovidConversationsParser.parseRedditComment)\n",
    ".filter(x => x != (\"\", \"\", \"\", false, \"\", \"\", \"\", -0.1, -1))\n",
    "rddComments.first()"
   ],
   "id": "72a3df9388606c92",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "//PART 1: Aggregate on temporal dimension and obtain percentage of posts classified as NSFW\n",
    "//Posts are :(id,subreddit.id,subreddit.name,subreddit.nsfw,created_utc,permalink,domain,url,selftext,title,score)\n",
    "/* solution is better using  reduceByKey becasue:\n",
    "    -Avoid collecting all values into memory before processing\n",
    "    -Perform aggregation as data is being processed\n",
    "    -Reduce network shuffle by combining data locally first\n",
    "*/\n",
    "val percentageNSFWPosts = rddPosts.map(x => (x._5, (1, if (x._4) 1 else 0))) // (created_utc, (posts count, nsfw flag))\n",
    ".reduceByKey ({ case ((total1, nsfw1), (total2, nsfw2)) =>\n",
    "(total1 + total2, nsfw1 + nsfw2)\n",
    "})\n",
    ".mapValues ({ case (total, nsfw) =>\n",
    "    //Calculate the percentage\n",
    "    val percentage = (nsfw.toDouble * 100) / total\n",
    "    \"Percentage NSFW Posts: \" + percentage + \"%\"\n",
    "})\n",
    "\n",
    "//.coalesce(1) //riduzione a singola partizione (per analisi, con singola partizione abbiamo singolo file da analizzare)\n",
    "//.collect()"
   ],
   "id": "3da2d28626ed6b5f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "//PART 2: Aggregate on temporal dimension and obtain average sentiment in comments and percentage of comments classified as NSFW\n",
    "//Comments are: (id,subreddit.id,subreddit.name,subreddit.nsfw,created_utc,permalink,body,sentiment,score)\n",
    "\n",
    "val avgSentimentWithNSFWComment = rddComments.map(x => (x._5, (if (x._4) 1 else 0, 1, x._8))) //(created_utc, nsfw flag, number of posts, sentiment)\n",
    ".reduceByKey((a, b) => (\n",
    "    a._1 + b._1,  // Sum NSFW counters\n",
    "    a._2 + b._2,  // Sum total post counters\n",
    "    a._3 + b._3   // Sum sentiment values\n",
    "))\n",
    ".mapValues(reduced => {\n",
    "    val (nsfwCount, totalCount, totalSentiment) = reduced\n",
    "    val nsfwPercentage = (nsfwCount * 100.0) / totalCount\n",
    "    val avgSentiment = totalSentiment / totalCount\n",
    "    (\"Percentage NSFW Comments: \"+ nsfwPercentage + \"%\", \"Average Sentiment: \" + avgSentiment)\n",
    "})\n",
    "//.coalesce(1) //riduzione a singola partizione (per analisi, con singola partizione abbiamo singolo file da analizzare)\n",
    "//.collect()"
   ],
   "id": "4fb46ae28cd213bf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "val path_output = \"../../../../output/covidPostCommentResults\"\n",
    "sc.getPersistentRDDs.foreach(_._2.unpersist())"
   ],
   "id": "aa9e94559d58d738",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "// PART 3: Join on Temporal Dimension and then write the output\n",
    "\n",
    "val finalResult = percentageNSFWPosts.join(avgSentimentWithNSFWComment) \n",
    "//with the join i get an Array[(String,(String,(String, String)))], in order to properly write it, i map it first then change it\n",
    ".map(x => (x._1, x._2._1, x._2._2._1, x._2._2._2))\n",
    ".coalesce(1) //riduzione a singola partizione (per analisi, con singola partizione abbiamo singolo file da analizzare)\n",
    ".toDF().write.format(\"csv\").mode(SaveMode.Overwrite).save(path_output)"
   ],
   "id": "afc6dfa8abb55193",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

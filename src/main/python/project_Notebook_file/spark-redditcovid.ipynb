{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-07T12:42:30.596869Z",
     "start_time": "2025-02-07T12:41:59.419987Z"
    }
   },
   "source": "import org.apache.spark",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://192.168.226.1:4040\n",
       "SparkContext available as 'sc' (version = 3.5.1, master = local[*], app id = local-1738932140359)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark\r\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T12:42:34.400291Z",
     "start_time": "2025-02-07T12:42:33.281505Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val path_to_bigDatasets = \"../../../../datasets/big/\"\n",
    "val path_to_datasets = \"../../../../datasets/\"\n",
    "\n",
    "val path_Fullml_posts = path_to_bigDatasets + \"the-reddit-covid-dataset-posts.csv\"\n",
    "val path_Fullml_comments = path_to_bigDatasets + \"the-reddit-covid-dataset-comments.csv\"\n",
    "\n",
    "val path_sample_posts = path_to_datasets + \"postsSample.csv\"\n",
    "val path_sample_comments = path_to_datasets + \"commentsSample.csv\""
   ],
   "id": "e3447d001ccfc3b4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "path_to_bigDatasets: String = ../../../../datasets/big/\r\n",
       "path_to_datasets: String = ../../../../datasets/\r\n",
       "path_Fullml_posts: String = ../../../../datasets/big/the-reddit-covid-dataset-posts.csv\r\n",
       "path_Fullml_comments: String = ../../../../datasets/big/the-reddit-covid-dataset-comments.csv\r\n",
       "path_sample_posts: String = ../../../../datasets/postsSample.csv\r\n",
       "path_sample_comments: String = ../../../../datasets/commentsSample.csv\r\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "f82e1326f40e4ea5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T12:49:14.594756Z",
     "start_time": "2025-02-07T12:49:13.933891Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import java.util.Calendar\n",
    "import org.apache.spark.sql.SaveMode\n",
    "import org.apache.spark.HashPartitioner\n",
    "\n",
    "object CovidConversationsParser {\n",
    "\n",
    "    val commaRegex = \",(?=(?:[^\\\"]*\\\"[^\\\"]*\\\")*[^\\\"]*$)\"\n",
    "    val pipeRegex = \"\\\\|(?=(?:[^\\\"]*\\\"[^\\\"]*\\\")*[^\\\"]*$)\"\n",
    "    val quotes = \"\\\"\"\n",
    "\n",
    "    /** Convert from timestamp (String) to year (Int) */\n",
    "    def yearFromTimestamp(timestamp: String): Int = {\n",
    "        val cal = Calendar.getInstance()\n",
    "        cal.setTimeInMillis(timestamp.trim.toLong * 1000L)\n",
    "        cal.get(Calendar.YEAR)\n",
    "    }\n",
    "\n",
    "    /** Function to parse reddit posts\n",
    "    *\n",
    "    *  @param line line that has to be parsed\n",
    "    *  @return tuple containing id,subreddit.id,subreddit.name,subreddit.nsfw,created_utc,permalink,domain,url,selftext,title,score. none in case of input errors\n",
    "    */\n",
    "    def parseRedditPost(line: String): Option[(String, String, String, Boolean, Int, String, String, String, String, String, Int)] = {\n",
    "        try {\n",
    "            val input = line.split(commaRegex)\n",
    "            if(input.size != 12) {\n",
    "                return Some((\"\", \"\", \"\", false, -1, \"\", \"\", \"\", \"\", \"\", -1))\n",
    "            }   \n",
    "            val url = if(input(8).trim.nonEmpty) input(8).trim else \"None\"\n",
    "            val selftext = if(input(9).trim.nonEmpty) input(9) else \"None\"\n",
    "            Some((input(1).trim, input(2).trim, input(3).trim, input(4).trim.toBoolean, yearFromTimestamp(input(5)), input(6).trim, input(7).trim, url, selftext, input(10).trim , input(11).trim.toInt))   \n",
    "        } catch {\n",
    "            case _: Exception => None\n",
    "        }\n",
    "    }\n",
    "\n",
    "    /** Function to parse reddit comments\n",
    "    *\n",
    "    *  @param line line that has to be parsed\n",
    "    *  @return tuple containing id,subreddit.id,subreddit.name,subreddit.nsfw,created_utc,permalink,body,sentiment,score. none in case of input errors\n",
    "    */\n",
    "    def parseRedditComment(line: String): Option[(String, String, String, Boolean, Int, String, String, Double, Int)] = {\n",
    "        try {\n",
    "            val input = line.split(commaRegex)\n",
    "            Some((input(1).trim, input(2).trim, input(3).trim, input(4).trim.toBoolean,yearFromTimestamp(input(5)), input(6).trim, input(7).trim, input(8).trim.toDouble, input(9).trim.toInt))\n",
    "        } catch {\n",
    "            case _: Exception => None\n",
    "        }\n",
    "    }\n",
    "}"
   ],
   "id": "c887d7e89a51786e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import java.util.Calendar\r\n",
       "import org.apache.spark.sql.SaveMode\r\n",
       "import org.apache.spark.HashPartitioner\r\n",
       "defined object CovidConversationsParser\r\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T12:51:56.805857Z",
     "start_time": "2025-02-07T12:51:56.474821Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val data = Array(1, 2, 3, 4, 5)\n",
    "val rddData = sc.parallelize(data)\n",
    "rddData.filter(x => x < 4).collect()"
   ],
   "id": "9b5e0aa76d4631f8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data: Array[Int] = Array(1, 2, 3, 4, 5)\r\n",
       "rddData: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[16] at parallelize at <console>:35\r\n",
       "res7: Array[Int] = Array(1, 2, 3)\r\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T12:20:19.155430Z",
     "start_time": "2025-02-07T12:20:18.993340Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val commaRegex = \",(?=(?:[^\\\"]*\\\"[^\\\"]*\\\")*[^\\\"]*$)\"\n",
    "val value = \"post,qfsoln,2qs1t,newyorkcity,false,1635202606,https://old.reddit.com/r/newyorkcity/comments/qfsoln/live_now_78pm_pix11_holds_their_2021_nyc_mayoral/,pix11.com,https://pix11.com/news/politics/new-york-elections/pix-on-politics-adams-sliwa-to-face-off-in-nyc-mayoral-forum-monday/,,\\\"Live Now (7-8PM): Pix11 holds their 2021 NYC mayoral forum, with frontrunner candidates Eric Adams (D), and Curtis Sliwa (R) answering questions on city issues such as COVID-19, vaccine mandates, schools, crime, youth violence and much more. (10/25/2021)\\\",1\"\n",
    "value.split(commaRegex).size"
   ],
   "id": "2a57888c5e50b341",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "commaRegex: String = ,(?=(?:[^\"]*\"[^\"]*\")*[^\"]*$)\r\n",
       "value: String = post,qfsoln,2qs1t,newyorkcity,false,1635202606,https://old.reddit.com/r/newyorkcity/comments/qfsoln/live_now_78pm_pix11_holds_their_2021_nyc_mayoral/,pix11.com,https://pix11.com/news/politics/new-york-elections/pix-on-politics-adams-sliwa-to-face-off-in-nyc-mayoral-forum-monday/,,\"Live Now (7-8PM): Pix11 holds their 2021 NYC mayoral forum, with frontrunner candidates Eric Adams (D), and Curtis Sliwa (R) answering questions on city issues such as COVID-19, vaccine mandates, schools, crime, youth violence and much more. (10/25/2021)\",1\r\n",
       "res84: Int = 12\r\n"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 110
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "517000d0f73409c2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "//per recuperare dei samples dei files\n",
    "//sc.textFile(path_Fullml_posts).sample(false, 0.05).coalesce(1).toDF().write.format(\"csv\").mode(SaveMode.Overwrite).save(\"../../../../datasets/sample\")\n",
    "sc.textFile(path_Fullml_comments).sample(false, 0.05).coalesce(1).toDF().write.format(\"csv\").mode(SaveMode.Overwrite).save(\"../../../../datasets/sample\")"
   ],
   "id": "6ef50ca52909c10e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T13:26:30.216827Z",
     "start_time": "2025-02-07T13:26:29.194930Z"
    }
   },
   "cell_type": "code",
   "source": [
    "/* se osserva qui prof, quando prendo semplicemente il primo elemento da quelli indicati, sembra perfettamente normale*/\n",
    "val rddPosts = sc.textFile(path_sample_posts)\n",
    "rddPosts.first()"
   ],
   "id": "14c684e2f81c5981",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rddPosts: org.apache.spark.rdd.RDD[String] = ../../../../datasets/postsSample.csv MapPartitionsRDD[29] at textFile at <console>:34\r\n",
       "res11: String = \"post,qftrls,4z7iqj,auscovid19,false,1635206035,https://old.reddit.com/r/AusCOVID19/comments/qftrls/queensland_records_two_new_community_covid19_cases/,abc.net.au,https://www.abc.net.au/news/2021-10-26/qld-coronavirus-covid-cases-home-quarantine-community/100551264,,Queensland records two new community COVID-19 cases,1\"\r\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T13:12:09.047632Z",
     "start_time": "2025-02-07T13:12:06.626065Z"
    }
   },
   "cell_type": "code",
   "source": [
    "/*se faccio qui la filter, ottengo però questo \"posted at 2020-05-11 17:15 CET by Rafael Antonio Pineda\" e non ho la minima idea del perchè????*/\n",
    "val rddPosts = sc.textFile(path_sample_posts).filter(x => x.startsWith(\"post\"))\n",
    "rddPosts.first()"
   ],
   "id": "32a8ea18bd746b6c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rddPosts: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[27] at filter at <console>:34\r\n",
       "res10: String = posted at 2020-05-11 17:15 CET by Rafael Antonio Pineda\r\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T12:53:49.826967Z",
     "start_time": "2025-02-07T12:53:39.416160Z"
    }
   },
   "cell_type": "code",
   "source": [
    "/*getting RDDs of Comments and Posts*/\n",
    "/* qui prof ho provato a cambiare il parser per fare sì che creasse delle tuple vuote se dopo lo split, non ottenevo 12 valori, eppure l unica cosa mi genera è una serie di queste tuple vuote, perche???*/\n",
    "val rddPosts = sc.textFile(path_sample_posts).flatMap(CovidConversationsParser.parseRedditPost)\n",
    "rddPosts.collect()"
   ],
   "id": "72a3df9388606c92",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "commaRegex: String = ,(?=(?:[^\"]*\"[^\"]*\")*[^\"]*$)\r\n",
       "rddPosts: org.apache.spark.rdd.RDD[(String, String, String, Boolean, Int, String, String, String, String, String, Int)] = MapPartitionsRDD[24] at flatMap at <console>:37\r\n",
       "res9: Array[(String, String, String, Boolean, Int, String, String, String, String, String, Int)] = Array((\"\",\"\",\"\",false,-1,\"\",\"\",\"\",\"\",\"\",-1), (\"\",\"\",\"\",false,-1,\"\",\"\",\"\",\"\",\"\",-1), (\"\",\"\",\"\",false,-1,\"\",\"\",\"\",\"\",\"\",-1), (\"\",\"\",\"\",false,-1,\"\",\"\",\"\",\"\",\"\",-1), (\"\",\"\",\"\",false,-1,\"\",\"\",\"\",\"\",\"\",-1), (\"\",\"\",\"\",false,-1,\"\",\"\",\"\",\"\",\"\",-1), (\"\",\"\",\"\",false,-1,\"\",\"\",\"\",\"\",\"\",-1), (\"\",\"\",\"\",false,-1,\"\",\"\",\"\",\"\",\"\",-1), (\"\",\"\",\"\",false,-1,\"\",\"\",\"\",\"\",\"\",-1), (\"\",\"\",\"\",false,-1,\"\",\"\",\"\",\"\",\"\",-1), (\"\",\"\",\"\",false,-1,\"\",\"\",\"\",\"\",\"\",-1), (\"\",\"\",\"\",false,-1,\"\",\"\",\"\",\"\",\"\",-1), (\"...\r\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "//PART 1: Aggregate on temporal dimension and obtain percentage of posts classified as NSFW\n",
    "//Posts are :(id,subreddit.id,subreddit.name,subreddit.nsfw,created_utc,permalink,domain,url,selftext,title,score)\n",
    "val percentageNSFWPosts = rddPosts.map(x => (x._5, (x._1, x._3, if (x._4) 1 else 0)))  // (created_utc, nsfw flag)\n",
    ".reduceByKey(_ + _)  // count NSFW posts per timestamp\n",
    ".mapValues(nsfwCount => {\n",
    "    val totalPostsAtTime = rddPosts.filter(y => y._5 == y._5).count()\n",
    "    (nsfwCount.toDouble / totalPostsAtTime) * 100\n",
    "})\n",
    "\n",
    "//.coalesce(1) //riduzione a singola partizione (per analisi, con singola partizione abbiamo singolo file da analizzare)\n",
    "//.collect()"
   ],
   "id": "ef8bd011160741f4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "val percentageNSFWPosts = rddPosts.map(x => (x._5, (x._1, x._3, if (x._4) 1 else 0)))  // (timestamp, (id, subreddit_name, nsfw flag)).aggregateByKey(\n",
    "    (0, 0)  // (nsfwCount, totalCount)\n",
    ")(\n",
    "    // Accumulator for each partition\n",
    "    (acc, value) => (acc._1 + value._3, acc._2 + 1),\n",
    "    // Combiner for merging partitions\n",
    "    (acc1, acc2) => (acc1._1 + acc2._1, acc1._2 + acc2._2)\n",
    ").map { case (timestamp, (nsfwCount, totalCount)) =>\n",
    "    val percentage = (nsfwCount.toDouble / totalCount) * 100\n",
    "    (timestamp, rddPosts.filter(_._5 == timestamp).first()._1,  // id\n",
    "    rddPosts.filter(_._5 == timestamp).first()._3,  // subreddit_name\n",
    "    percentage)\n",
    "}"
   ],
   "id": "8430eb481a126db3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "//PART 2: Aggregate on temporal dimension and obtain average sentiment in comments and percentage of comments classified as NSFW\n",
    "//Comments are: (id,subreddit.id,subreddit.name,subreddit.nsfw,created_utc,permalink,body,sentiment,score)\n",
    "val avgSentimentWithNSFWPost = rddComments.map(x => (x._5, (if (x._4) 1 else 0, x._8)))  // (created_utc, (nsfw flag, sentiment))\n",
    ".reduceByKey((a, b) => (a._1 + b._1, a._2 + b._2))  // aggregate NSFW count and sentiment\n",
    ".mapValues(avgSentimentAndNSFWCount => {\n",
    "    val totalCommentsAtTime = rddComments.filter(y => y._5 == y._5).count()\n",
    "    val nsfwPercentage = (avgSentimentAndNSFWCount._1.toDouble / totalCommentsAtTime) * 100\n",
    "    val avgSentiment = avgSentimentAndNSFWCount._2 / totalCommentsAtTime\n",
    "    (nsfwPercentage, avgSentiment)\n",
    "})"
   ],
   "id": "32eee082e5a2a05a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "// PART 3: Join on Temporal Dimension\n",
    "val finalResult = percentageNSFWPosts.join(avgSentimentWithNSFWPost)"
   ],
   "id": "afc6dfa8abb55193",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e99b6b25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T15:34:09.444324Z",
     "iopub.status.busy": "2022-02-28T15:34:09.441785Z",
     "iopub.status.idle": "2022-02-28T15:34:10.302913Z",
     "shell.execute_reply": "2022-02-28T15:34:10.302209Z",
     "shell.execute_reply.started": "2022-02-28T15:34:09.444282Z"
    }
   },
   "source": [
    "# 104 Spark - Movielens\n",
    "\n",
    "The goal of this lab is to run some analysis on a different dataset, [MovieLens](https://grouplens.org/datasets/movielens/), on AWS.\n",
    "\n",
    "- [Spark programming guide](https://spark.apache.org/docs/latest/rdd-programming-guide.html)\n",
    "- [RDD APIs](https://spark.apache.org/docs/latest/api/scala/org/apache/spark/rdd/RDD.html)\n",
    "- [PairRDD APIs](https://spark.apache.org/docs/latest/api/scala/org/apache/spark/rdd/PairRDDFunctions.html)\n",
    "\n",
    "**Download the dataset** from [here](https://big.csr.unibo.it/downloads/bigdata/ml-dataset.zip), unzip it and put it in the ```datasets/big``` folder.\n",
    "\n",
    "- ml-movies.csv (<u>movieId</u>:Long, title:String, genres:String) \n",
    "    - genres are separated by pipelines  (e.g., \"comedy|drama|action\")\n",
    "    - each movie is associated with many ratings\n",
    "\n",
    "- ml-ratings.csv (<u>userId</u>:Long, <u>movieId</u>:Long, rating:Double, year:Int)\n",
    "    - each rating is associated with many tags\n",
    "    - ml-ratings-sample.csv is a small sample of ml-ratings.csv, useful for developing\n",
    "- ml-tags.csv (<u>userId</u>:Long, <u>movieId</u>:Long, <u>tag</u>:String, year:Int) "
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T10:56:54.235664Z",
     "start_time": "2024-11-20T10:56:41.444320Z"
    }
   },
   "cell_type": "code",
   "source": "import org.apache.spark",
   "id": "c2b673a91143a3bd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://LAPTOP-T2P39KLE:4041\n",
       "SparkContext available as 'sc' (version = 3.5.1, master = local[*], app id = local-1732100206921)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark\r\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "6297e3f5-17d3-44ba-a06c-8b1acf0ca078",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-11-20T10:56:57.093936Z",
     "start_time": "2024-11-20T10:56:56.198452Z"
    }
   },
   "source": [
    "val path_to_datasets = \"../../../../datasets/big/\"\n",
    "\n",
    "val path_ml_movies = path_to_datasets + \"ml-movies.csv\"\n",
    "val path_ml_ratings = path_to_datasets + \"ml-ratings-sample.csv\"\n",
    "val path_ml_tags = path_to_datasets + \"ml-tags.csv\""
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "path_to_datasets: String = ../../../../datasets/big/\r\n",
       "path_ml_movies: String = ../../../../datasets/big/ml-movies.csv\r\n",
       "path_ml_ratings: String = ../../../../datasets/big/ml-ratings-sample.csv\r\n",
       "path_ml_tags: String = ../../../../datasets/big/ml-tags.csv\r\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "e643e27d-b710-43cb-bc3d-7bca65e93b15",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-11-20T10:57:04.193672Z",
     "start_time": "2024-11-20T10:57:02.813548Z"
    }
   },
   "source": [
    "import java.util.Calendar\n",
    "import org.apache.spark.sql.SaveMode\n",
    "import org.apache.spark.HashPartitioner\n",
    "\n",
    "object MovieLensParser {\n",
    "\n",
    "  val noGenresListed = \"(no genres listed)\"\n",
    "  val commaRegex = \",(?=(?:[^\\\"]*\\\"[^\\\"]*\\\")*[^\\\"]*$)\"\n",
    "  val pipeRegex = \"\\\\|(?=(?:[^\\\"]*\\\"[^\\\"]*\\\")*[^\\\"]*$)\"\n",
    "  val quotes = \"\\\"\"\n",
    "  \n",
    "  /** Convert from timestamp (String) to year (Int) */\n",
    "  def yearFromTimestamp(timestamp: String): Int = {\n",
    "    val cal = Calendar.getInstance()\n",
    "    cal.setTimeInMillis(timestamp.trim.toLong * 1000L)\n",
    "    cal.get(Calendar.YEAR)\n",
    "  }\n",
    "\n",
    "  /** Function to parse movie records\n",
    "   *\n",
    "   *  @param line line that has to be parsed\n",
    "   *  @return tuple containing movieId, title and genres, none in case of input errors\n",
    "   */\n",
    "  def parseMovieLine(line: String): Option[(Long, String, String)] = {\n",
    "    try {\n",
    "      val input = line.split(commaRegex)\n",
    "      var title = input(1).trim\n",
    "      title = if(title.startsWith(quotes)) title.substring(1) else title\n",
    "      title = if(title.endsWith(quotes)) title.substring(0, title.length - 1) else title\n",
    "      Some(input(0).trim.toLong, title, input(2).trim)\n",
    "    } catch {\n",
    "      case _: Exception => None\n",
    "    }\n",
    "  }\n",
    "\n",
    "  /** Function to parse rating records\n",
    "   *\n",
    "   *  @param line line that has to be parsed\n",
    "   *  @return tuple containing userId, movieId, rating, and year none in case of input errors\n",
    "   */\n",
    "  def parseRatingLine(line: String): Option[(Long, Long, Double, Int)] = {\n",
    "    try {\n",
    "      val input = line.split(commaRegex)\n",
    "      Some(input(0).trim.toLong, input(1).trim.toLong, input(2).trim.toDouble, yearFromTimestamp(input(3)))\n",
    "    } catch {\n",
    "      case _: Exception => None\n",
    "    }\n",
    "  }\n",
    "\n",
    "  /** Function to parse tag records\n",
    "   *\n",
    "   *  @param line line that has to be parsed\n",
    "   *  @return tuple containing userId, movieId, tag, and year, none in case of input errors\n",
    "   */\n",
    "  def parseTagLine(line: String) : Option[(Long, Long, String, Int)] = {\n",
    "    try {\n",
    "      val input = line.split(commaRegex)\n",
    "      Some(input(0).trim.toLong, input(1).trim.toLong, input(2), yearFromTimestamp(input(3)))\n",
    "    } catch {\n",
    "      case _: Exception => None\n",
    "    }\n",
    "  }\n",
    "\n",
    "}"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import java.util.Calendar\r\n",
       "import org.apache.spark.sql.SaveMode\r\n",
       "import org.apache.spark.HashPartitioner\r\n",
       "defined object MovieLensParser\r\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "3e69ae6f-50f6-4e2f-9fe8-ff6d747e675f",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-11-20T10:57:14.989343Z",
     "start_time": "2024-11-20T10:57:13.471755Z"
    }
   },
   "source": [
    "val rddMovies = sc.textFile(path_ml_movies).flatMap(MovieLensParser.parseMovieLine)\n",
    "val rddRatings = sc.textFile(path_ml_ratings).flatMap(MovieLensParser.parseRatingLine)\n",
    "val rddTags = sc.textFile(path_ml_tags).flatMap(MovieLensParser.parseTagLine)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rddMovies: org.apache.spark.rdd.RDD[(Long, String, String)] = MapPartitionsRDD[2] at flatMap at <console>:32\r\n",
       "rddRatings: org.apache.spark.rdd.RDD[(Long, Long, Double, Int)] = MapPartitionsRDD[5] at flatMap at <console>:33\r\n",
       "rddTags: org.apache.spark.rdd.RDD[(Long, Long, String, Int)] = MapPartitionsRDD[8] at flatMap at <console>:34\r\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "d9dfbdfd-2ee7-4488-a95f-9f1f809e581c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T15:59:00.715374Z",
     "iopub.status.busy": "2022-02-28T15:59:00.715148Z",
     "iopub.status.idle": "2022-02-28T15:59:01.005430Z",
     "shell.execute_reply": "2022-02-28T15:59:01.004685Z",
     "shell.execute_reply.started": "2022-02-28T15:59:00.715351Z"
    },
    "tags": []
   },
   "source": [
    "## 104-1 Datasets exploration\n",
    "\n",
    "Cache the datasets and answer the following questions:\n",
    "\n",
    "- How many (distinct) users, movies, ratings, and tags?\n",
    "- How many (distinct) genres?\n",
    "- On average, how many ratings per user?\n",
    "- On average, how many ratings per movie?\n",
    "- On average, how many genres per movie?\n",
    "- What is the range of ratings?\n",
    "- Which years? (print an ordered list)\n",
    "- On average, how many ratings per year?\n",
    "\n",
    "Try these locally as \"extra\" exercises; solutions will be published later on."
   ]
  },
  {
   "cell_type": "code",
   "id": "1f07a5b9-baaf-4564-8988-33e23ced42ea",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-11-20T10:14:52.544965Z",
     "start_time": "2024-11-20T10:14:52.211856Z"
    }
   },
   "source": [
    "val rddMoviesCached = rddMovies.cache()\n",
    "val rddRatingsCached = rddRatings.cache()\n",
    "val rddTagsCached = rddTags.cache()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rddMoviesCached: rddMovies.type = MapPartitionsRDD[2] at flatMap at <console>:32\r\n",
       "rddRatingsCached: rddRatings.type = MapPartitionsRDD[5] at flatMap at <console>:33\r\n",
       "rddTagsCached: rddTags.type = MapPartitionsRDD[8] at flatMap at <console>:34\r\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "9a4016ac-cb34-48d0-a45c-29122e5fa59a",
   "metadata": {},
   "source": [
    "## 104-2 Compute the average rating for each movie\n",
    "\n",
    "- Export the result to a file\n",
    "- Do not start from cached RDDs\n",
    "- Evaluate:\n",
    "  - Join-and-Aggregate\n",
    "  - Aggregate-and-Join\n",
    "  - Aggregate-and-BroadcastJoin"
   ]
  },
  {
   "cell_type": "code",
   "id": "feb49547-58f9-4994-929a-da867e2e4cc6",
   "metadata": {
    "tags": []
   },
   "source": [
    "val path_output_avgRatPerMovie = \"../../../../output/avgRatPerMovie\"\n",
    "// rdd.coalesce(1).toDF().write.format(\"csv\").mode(SaveMode.Overwrite).save(path_output_avgRatPerMovie)\n",
    "\n",
    "sc.getPersistentRDDs.foreach(_._2.unpersist())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "dd4fdb9c-7a73-43a0-a121-fe98dc71ea02",
   "metadata": {},
   "source": "### Join-and-Aggregate"
  },
  {
   "cell_type": "code",
   "id": "35060678-a714-4871-a0ee-bd6d1149c2c9",
   "metadata": {
    "tags": []
   },
   "source": [
    "val rddMoviesKV = rddMovies.map(x => (x._1,x._2)) //chiave-valore (id, titolo)\n",
    "val avgRatPerMovie = rddRatings.\n",
    "    map(x => ((x._2),(x._3))). //chiave-valore (id, rating)\n",
    "    join(rddMoviesKV). //join fatta su id => (movieID, (rating, title))\n",
    "    map({case (m,(r,t)) => ((m,t),r)}). //((movieID, title) rating)\n",
    "    aggregateByKey((0.0,0.0))((a,v)=>(a._1+v, a._2+1),(a1,a2)=>(a1._1+a2._1,a1._2+a2._2)).\n",
    "    map({case ((m,t),(sum,cnt)) => (m, t, sum/cnt, cnt)}). //mappa per avere l'average => ((movieID, title),(average,count))\n",
    "    coalesce(1). //riduzione a singola partizione (per analisi, con singola partizione abbiamo singolo file da analizzare)\n",
    "    toDF().write.format(\"csv\").mode(SaveMode.Overwrite).save(path_output_avgRatPerMovie) //per ritornare output come file csv"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Aggregate-and-Join",
   "id": "f30a78f233f9cdaf"
  },
  {
   "cell_type": "code",
   "id": "45bddac2-b5b0-4eee-b34d-312877a7262e",
   "metadata": {},
   "source": [
    "val rddMoviesKV = rddMovies.map(x => (x._1,x._2))\n",
    "val avgRatPerMovie = rddRatings.\n",
    "    map(x => (x._2,x._3)).\n",
    "    aggregateByKey((0.0,0.0))((a,v)=>(a._1+v, a._2+1),(a1,a2)=>(a1._1+a2._1,a1._2+a2._2)).\n",
    "    mapValues({case (sum,cnt) => (sum/cnt, cnt)}).\n",
    "    join(rddMoviesKV).\n",
    "    map({case (m,((r,cnt),t)) => (m,t,r,cnt)}).\n",
    "    coalesce(1).\n",
    "    toDF().write.format(\"csv\").mode(SaveMode.Overwrite).save(path_output_avgRatPerMovie)\n",
    "\n",
    "//avgRatPerMovie.toDebugString"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "887bbb2f-5b97-4918-ae8c-dd98f252a6e6",
   "metadata": {},
   "source": "### Aggregate-and-BroadcastJoin"
  },
  {
   "cell_type": "code",
   "id": "d17c7e50-802a-46e7-b522-2269e23c0085",
   "metadata": {
    "tags": []
   },
   "source": [
    "// circa stesso numero di shuffling, poichè rimuoviamo lavoro shuffling di join, ma rimane quello di aggregate e vi sono comunque lavori dovuti a broadcast (non è ottimizzato tanto di più rispetto a soluzioni precedenti)\n",
    "val rddMoviesKV = rddMovies.map(x => (x._1,x._2))\n",
    "val bRddMovies = sc.broadcast(rddMoviesKV.collectAsMap())\n",
    "val avgRatPerMovie = rddRatings.\n",
    "    map(x => ((x._2),(x._3))).\n",
    "    aggregateByKey((0.0,0.0))((a,v)=>(a._1+v, a._2+1),(a1,a2)=>(a1._1+a2._1,a1._2+a2._2)).\n",
    "    mapValues({case (sum,cnt) => (sum/cnt, cnt)}).\n",
    "    map({case (m,(r,cnt)) => (m,bRddMovies.value.get(m),r,cnt)}).\n",
    "    coalesce(1).\n",
    "    toDF().write.format(\"csv\").mode(SaveMode.Overwrite).save(path_output_avgRatPerMovie)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c07050d2-4447-4765-814d-2cd0ff1402c1",
   "metadata": {},
   "source": [
    "## 104-3 Compute the average rating for each genre\n",
    "\n",
    "Two possible workflows:\n",
    "\n",
    "1. Pre-aggregation (3 shuffles)\n",
    "\n",
    "  - Aggregate ratings by movieId\n",
    "  - Join with movies and map to genres\n",
    "  - Aggregate by genres\n",
    "  \n",
    "2. Join & aggregate (2 shuffles)\n",
    "\n",
    "  - Join with movies and map to genres\n",
    "  - Aggregate by genres"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T10:38:57.187746Z",
     "start_time": "2024-11-20T10:38:56.899087Z"
    }
   },
   "cell_type": "code",
   "source": [
    "//val path_output_avgRatPerGenre = \"s3a://\"+bucketname+\"/spark/avgRatPerGenre\"\n",
    "val path_output_avgRatPerGenre = \"../../../../output/avgRatPerGenre\"\n",
    "sc.getPersistentRDDs.foreach(_._2.unpersist())\n",
    "/*for ((k,v) <- sc.getPersistentRDDs) {\n",
    "  v.unpersist()\n",
    "}*/"
   ],
   "id": "1c6cf967ed75fcf",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "path_output_avgRatPerGenre: String = ../../../../output/avgRatPerGenre\r\n"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T10:58:35.828549Z",
     "start_time": "2024-11-20T10:58:27.262096Z"
    }
   },
   "cell_type": "code",
   "source": [
    "//MOVIES : (movieID, title, genre)\n",
    "// (movieID, genre)\n",
    "//RATINGS: (userID,movieID,rating,timestamp)\n",
    "//TAGS: (userID,movieID,tag,timestamp)\n",
    "\n",
    "// ci serve fare una flatmap dei generi, per vedere se più film hanno stessi valori del genere\n",
    "// in una maniera similare all'esercizio Inverted index (sentence-based offset) del lab02, specifico il caso\n",
    "// indicando i 3 valori iniziali passati, faccio uno split dei valori dei generi, e per ogni genere mappo id del film\n",
    "val rddMoviesIDGenre = rddMovies.flatMap({case (id,title,genre) => genre.split('|').map(g => (id, g))})\n",
    "val avgRatPerGenre = rddRatings.\n",
    "        map(x => ((x._2),(x._3))). //chiave-valore (id, rating)\n",
    "        join(rddMoviesIDGenre). //join fatta su id => (movieID, (rating, genre))\n",
    "        map({case (m,(r,t)) => ((m,t),r)}). //((movieID, genre) rating)\n",
    "        // aggregate specifica aspetti di combine e di reduce\n",
    "        aggregateByKey((0.0,0.0))((a,v)=>(a._1+v, a._2+1),(a1,a2)=>(a1._1+a2._1,a1._2+a2._2)).\n",
    "        map({case ((m,t),(sum,cnt)) => (m, t, sum/cnt, cnt)}). //mappa per avere l'average => ((movieID, genre),(average,count))\n",
    "        coalesce(1). //riduzione a singola partizione (per analisi, con singola partizione abbiamo singolo file da analizzare)\n",
    "        collect()\n",
    "//toDF().write.format(\"csv\").mode(SaveMode.Overwrite).save(path_output_avgRatPerGenre) //per ritornare output come file csv"
   ],
   "id": "96d8ae65e32f7e5d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rddMoviesIDGenre: org.apache.spark.rdd.RDD[(Long, String)] = MapPartitionsRDD[9] at flatMap at <console>:37\r\n",
       "avgRatPerGenre: Array[(Long, String, Double, Double)] = Array((4018,Comedy,3.100886917960089,451.0), (86332,Drama,3.4720394736842106,304.0), (187023,Documentary,4.0,2.0), (155832,Thriller,4.5,1.0), (44234,Sci-Fi,0.5,1.0), (3412,Adventure,2.95,40.0), (188189,Comedy,4.5,1.0), (34450,Drama,2.1666666666666665,3.0), (114242,Horror,1.75,2.0), (127140,Drama,3.45,10.0), (2950,Drama,2.5925925925925926,162.0), (101614,Drama,3.5,2.0), (8684,Drama,4.09375,16.0), (8676,Action,1.25,2.0), (4005,Thriller,3.172043010752688,93.0), (104144,Animation,2.5,2.0), (4176,Drama,3.5,4.0), (4643,Adventure,2.825358851674641,418.0), (59336,Action,3.4375,16.0), (8197,Drama,3.9523809523809526,21.0), (48575,Film...\r\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ef540e8ff0a8579f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
